{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions' from 'c:\\\\Applied AI\\\\Applied_AI\\\\Applied AI project\\\\functions.py'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import pandas as pd \n",
    "import functions as func\n",
    "import importlib\n",
    "importlib.reload(func)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationNN(nn.Module):\n",
    "    def __init__(self,num_features,num_targets):\n",
    "        super(ClassificationNN, self).__init__()\n",
    "\n",
    "        self.num_featurs = num_features\n",
    "        self.num_targets = num_targets\n",
    "        \n",
    "        self.fc1 = nn.Linear(num_features,128)\n",
    "        self.fc2 = nn.Linear(128,128)\n",
    "\n",
    "        if num_targets == 2:\n",
    "            self.output = nn.Linear(128,1)\n",
    "        else:\n",
    "            self.output = nn.Linear(128,num_targets)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "            \n",
    "        if self.num_targets == 2:\n",
    "            x = torch.sigmoid(x)\n",
    "        #No need if num_targets is not binary (cross entropy loss applied from the outside)\n",
    "        \n",
    "        return x \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_sv_classification_model(dataset,epochs,n_splits):\n",
    "\n",
    "    data,target,num_targets,num_features = func.read_data(dataset)\n",
    "\n",
    "    model = ClassificationNN(num_features, num_targets=num_targets)\n",
    "    learning_rate=0.001\n",
    "\n",
    "    model.train()\n",
    "    running_loss=0\n",
    "\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(data.drop(target,axis=1), data[target], test_size=0.33, random_state=42)\n",
    "\n",
    "    skf = KFold(n_splits=n_splits)\n",
    "\n",
    "    fold = 0\n",
    "    fold_accuracies = []\n",
    "\n",
    "    for train_index, val_index in skf.split(X_train_val,y_train_val):\n",
    "        X_train,X_val = func.convert_df_to_tensor([X_train_val.iloc[train_index],X_train_val.iloc[val_index]])\n",
    "        y_train,y_val = func.convert_df_to_tensor([y_train_val.iloc[train_index],y_train_val.iloc[val_index]])\n",
    "\n",
    "        train_loader = func.convert_to_dataloader(X_train,y_train)\n",
    "        val_loader = func.convert_to_dataloader(X_val,y_val)\n",
    "\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "        \n",
    "        if num_targets == 2:\n",
    "            criterion = nn.BCELoss() \n",
    "        else:\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        for epoch in range(1,epochs+1):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_X)\n",
    "                if num_targets == 2:\n",
    "                    loss = criterion(outputs, batch_y.unsqueeze(1).float())\n",
    "                else:\n",
    "                    loss = criterion(outputs, batch_y.long())\n",
    "\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            avg_loss = running_loss / len(train_loader)\n",
    "            \n",
    "            if epoch % 10 == 0 or epoch == 1:\n",
    "                print(f'Epoch [{epoch}/{epochs}], Loss: {avg_loss:.4f}')            \n",
    "        \n",
    "        #Test model\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total =0 \n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_x,batch_y in val_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_X)\n",
    "\n",
    "                if num_targets == 2:\n",
    "                    \n",
    "                    predicted = (outputs > 0.5).float()\n",
    "                    correct += (predicted.squeeze(1) == batch_y.float()).sum().item()\n",
    "                else:\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs, dim=1)\n",
    "                    correct += (predicted == batch_y.long()).sum().item()\n",
    "                total += batch_y.size(0)\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Fold {fold} Accuracy: {accuracy:.2f}% for dataset {dataset}')\n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold += 1\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_sv_classification_model(dataset,model):\n",
    "\n",
    "    data,target,num_targets,num_features = func.read_data(dataset)\n",
    "    \n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(data.drop(target,axis=1), data[target], test_size=0.33, random_state=42)\n",
    "\n",
    "    X_test = func.convert_df_to_tensor(X_test)\n",
    "    y_test = func.convert_df_to_tensor(y_test)\n",
    "\n",
    "    eval_loader = func.convert_to_dataloader(X_test,y_test)\n",
    "        \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "                   \n",
    "    #Test model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total =0 \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x,batch_y in eval_loader:\n",
    "            batch_X, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "\n",
    "            if num_targets == 2:\n",
    "                \n",
    "                predicted = (outputs > 0.5).float()\n",
    "                correct += (predicted.squeeze(1) == batch_y.float()).sum().item()\n",
    "            else:\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                correct += (predicted == batch_y.long()).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}% for dataset {dataset}')\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 1.8557\n",
      "Fold 0 Accuracy: 38.61% for dataset ecoli\n",
      "Epoch [1/2], Loss: 0.6323\n",
      "Fold 1 Accuracy: 62.10% for dataset ecoli\n",
      "Epoch [1/2], Loss: 100.7625\n",
      "Fold 0 Accuracy: 25.47% for dataset dry_bean\n",
      "Epoch [1/2], Loss: 1.9452\n",
      "Fold 1 Accuracy: 26.96% for dataset dry_bean\n",
      "Epoch [1/2], Loss: 1.2243\n",
      "Fold 0 Accuracy: 32.86% for dataset seeds\n",
      "Epoch [1/2], Loss: 0.8748\n",
      "Fold 1 Accuracy: 34.29% for dataset seeds\n",
      "Epoch [1/2], Loss: 1.2732\n",
      "Fold 0 Accuracy: 48.75% for dataset cover_type\n",
      "Epoch [1/2], Loss: 1.2102\n",
      "Fold 1 Accuracy: 48.76% for dataset cover_type\n",
      "Epoch [1/2], Loss: 6.3347\n",
      "Fold 0 Accuracy: 94.01% for dataset ozone\n",
      "Epoch [1/2], Loss: 5.9871\n",
      "Fold 1 Accuracy: 93.85% for dataset ozone\n"
     ]
    }
   ],
   "source": [
    "datasets = {'ecoli':[30,5],'dry_bean':[30,5],'seeds':[30,5],'cover_type':[10,2],'ozone':[30,5]}\n",
    "model_dict = {}\n",
    "for dataset_name,param_list in datasets.items:\n",
    "    model_dict[dataset_name] = train_sv_classification_model(dataset_name,*param_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.10% for dataset ecoli\n",
      "Accuracy: 25.73% for dataset dry_bean\n",
      "Accuracy: 74.29% for dataset seeds\n",
      "Accuracy: 48.76% for dataset cover_type\n",
      "Accuracy: 91.31% for dataset ozone\n"
     ]
    }
   ],
   "source": [
    "accuracy_dict = {}\n",
    "for dataset,model in model_dict.items():\n",
    "    accuracy_dict[dataset] = evaluate_sv_classification_model(dataset,model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'landmass', 'zone', 'area', 'population', 'language',\n",
       "       'religion', 'bars', 'stripes', 'colours', 'red', 'green', 'blue',\n",
       "       'gold', 'white', 'black', 'orange', 'mainhue', 'circles', 'crosses',\n",
       "       'saltires', 'quarters', 'sunstars', 'crescent', 'triangle', 'icon',\n",
       "       'animate', 'text', 'topleft', 'botright', 'black', 'blue', 'gold',\n",
       "       'green', 'orange', 'red', 'white', 'black', 'blue', 'brown', 'gold',\n",
       "       'green', 'orange', 'red', 'white'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>5.137</td>\n",
       "      <td>2.981</td>\n",
       "      <td>3.631</td>\n",
       "      <td>4.870</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>5.140</td>\n",
       "      <td>2.795</td>\n",
       "      <td>4.325</td>\n",
       "      <td>5.003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>13.20</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.232</td>\n",
       "      <td>8.315</td>\n",
       "      <td>5.056</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11.84</td>\n",
       "      <td>13.21</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>5.175</td>\n",
       "      <td>2.836</td>\n",
       "      <td>3.598</td>\n",
       "      <td>5.044</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12.30</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>5.243</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.637</td>\n",
       "      <td>5.063</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1       2      3      4      5      6  7\n",
       "0    15.26  14.84  0.8710  5.763  3.312  2.221  5.220  1\n",
       "1    14.88  14.57  0.8811  5.554  3.333  1.018  4.956  1\n",
       "2    14.29  14.09  0.9050  5.291  3.337  2.699  4.825  1\n",
       "3    13.84  13.94  0.8955  5.324  3.379  2.259  4.805  1\n",
       "4    16.14  14.99  0.9034  5.658  3.562  1.355  5.175  1\n",
       "..     ...    ...     ...    ...    ...    ...    ... ..\n",
       "205  12.19  13.20  0.8783  5.137  2.981  3.631  4.870  3\n",
       "206  11.23  12.88  0.8511  5.140  2.795  4.325  5.003  3\n",
       "207  13.20  13.66  0.8883  5.236  3.232  8.315  5.056  3\n",
       "208  11.84  13.21  0.8521  5.175  2.836  3.598  5.044  3\n",
       "209  12.30  13.34  0.8684  5.243  2.974  5.637  5.063  3\n",
       "\n",
       "[210 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/seeds/seeds_dataset.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
